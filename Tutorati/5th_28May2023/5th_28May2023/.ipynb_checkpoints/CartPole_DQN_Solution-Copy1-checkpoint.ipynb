{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> CartPole, Deep Q-learning solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - The learning cycle\n",
    "\n",
    "We start by defining a generic learning cycle for a gym-like environment (not specific of the CartPole problem). A \"brain\" defined later contains all the details of the learning algorithm. In this specific case we will implement a Deep Q-Learning algorithm.\n",
    "\n",
    "The pseudo-code of the learning cycle is:\n",
    "\n",
    "- for episode until the stop_rule is satisfied:\n",
    "> - reset the environment to the starting state   \n",
    "> - for each step in the episode (until any terminal state has been reached)   \n",
    "> > - choose an expolartion probability according to the *epsilon\\_greedy\\_rule*\n",
    "> > - select an action $a_t$ as defined by the learning brain, *brain.act*, and by knowing the exploration probability\n",
    "> > - execute the action $a_t$ and observe reward $r_{t+1}$ and  the new state $s_{t+1}$  \n",
    "> > - save the experience $e_t = \\{s_t,a_t,r_{t+1},s_{t+1}\\}$ in the brain memory, *brain.remember*\n",
    "> > - train the brain according to the stored experience *brain.train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn(env, brain, stop_rule, epsilon_greedy_rule, print_every_ep=5):\n",
    "\n",
    "    reward_trajectory = []\n",
    "    training_step = 0 # Number of updates taht the NN performs\n",
    "    \n",
    "    while True: # Cycle over all the episodes until a stop_rule is satisfied\n",
    "        \n",
    "        if stop_rule(training_step, reward_trajectory): # Check the training end\n",
    "            break \n",
    "            \n",
    "        state = env.reset() # Reset environment\n",
    "        ep_reward = 0 # Reset the score for this episode.\n",
    "        \n",
    "        while True: # Cycle over the episode steps\n",
    "\n",
    "            explore_p = epsilon_greedy_rule(training_step) # Epsilon greedy scheduling\n",
    "            action = brain.act(state, explore_p) # Get action\n",
    "            next_state, reward, done, _ = env.step(action) # Take action\n",
    "            ep_reward += reward # Accumulate reward\n",
    "\n",
    "            if done: # Episode is completed -- failure or max number of steps reached (success)\n",
    "                reward_trajectory.append(ep_reward)\n",
    "                # Add experience to bucket (next_state is None since episode is over).\n",
    "                brain.remember(state, action, None, reward)\n",
    "                if len(reward_trajectory) % print_every_ep == 0:\n",
    "                    print(\"Episode: {}, Steps: {}, Last reward: {}, Explore P: {}\".format(len(reward_trajectory), training_step, ep_reward, explore_p))\n",
    "                break\n",
    "\n",
    "            brain.remember(state, action, next_state, reward) # Store tuple.\n",
    "            state = next_state # Advance state\n",
    "            brain.train() # Train the network from replay samples.\n",
    "            training_step += 1\n",
    "                \n",
    "    return reward_trajectory\n",
    "\n",
    "\n",
    "# This is for testing a trained model\n",
    "def Test(env, NN_keras_model, max_n_steps, render=True):\n",
    "    \n",
    "    env._max_episode_steps = max_n_steps\n",
    "    state = env.reset()\n",
    "    ep_reward = 0\n",
    "    \n",
    "    while True: # Cycle over the episode steps\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = np.argmax(NN_keras_model.predict(np.array([state]))) # Get action without exploration\n",
    "        next_state, reward, done, _ = env.step(action) # Take action\n",
    "        ep_reward += reward # Accumulate reward\n",
    "        state = next_state # Advance state\n",
    "        if done: # Episode is completed -- failure or max number of steps reached (success)\n",
    "            print(\"Total reward: {}\".format(ep_reward))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - The neural network\n",
    "The contiuous state space of the CartPole environemnt does not allow for a tabular learning of the quality function.\n",
    "A typical approach in such cases is to use a neural network as a funcion approximator for the quality function, which has the state as input (4 input nodes, corresponding to the 4 dimensions of the state space), and returns the quality of each action as output (2 output nodes, i.e. push left or push right).\n",
    "\n",
    "<center> $Q(\\; \\vec{s} \\;, \\text{push left}) \\sim \\text{first output node of the neural network}(\\; \\vec{s}\\; )$\n",
    "    \n",
    "<center> $Q(\\; \\vec{s} \\;, \\text{push right}) \\sim \\text{second output node of the neural network}(\\; \\vec{s}\\; )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "\n",
    "def build_NN(input_dim, output_dim, adam_learning_rate):\n",
    "    \"\"\"\n",
    "    Bulding the neural network as a keras model. The network has specified number of input and output nodes.\n",
    "    Is has 2 hidden layers composed of 128 units. All the layers are dense.\n",
    "    Activation functions are relu for the hidden layers , and linear for the output layer.\n",
    "    The loss function that the network tries to minimize is a mean squared error.\n",
    "    The weights are updated with the ADAM optimizer (an improvement of GD which \n",
    "    also considers information about the second moment of the error to adaptively change the \n",
    "    learning rate).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the four layers of the neural network\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    h1 = Dense(100, activation=\"relu\")(input_layer)\n",
    "    h2 = Dense(100, activation=\"relu\")(h1)        \n",
    "    output_layer = Dense(output_dim, activation=\"linear\")(h2)\n",
    "    \n",
    "    # Putting the layers together and specifying the loss function and the GD algorithm.\n",
    "    model = Model(input_layer, output_layer) \n",
    "    model.compile(loss=\"mse\", optimizer=Adam(lr=adam_learning_rate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two methods that you need to train the network in our reinforcement learning setting are *predict* and *fit*. For the documentation see: https://keras.io/models/model/.\n",
    "\n",
    "*Predict(state)* returns the output associated to the input, i.e. the quality of the two actions given the state, according to the current configuration of weights.\n",
    "\n",
    "*Fit(state, $\\hat{Q}$)* trains the network given a list of inputs / states and their labels / estimated Q values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - The Deep Q-learning brain\n",
    "\n",
    "The following class will deifine a proper object which will be passed to the learning cycle above and contains the deep Q-learning algorithm.\n",
    "\n",
    "The following functions of the brain are called at different moments of the learning cycle (as described above):\n",
    "- *act(state, $\\epsilon$)*: returns the action given the state and the episode. There is an epsilon-greedy exploration: with probability $\\epsilon$ the action is chosen at random, otherwise the argmax of the quality is selected.\n",
    "- *remember(state, action, next_state, reward)*: add to the memory the tuple of observation. Only the last $\\text{mem_size}$ observations are stored.\n",
    "- *train()*:\n",
    "> - sample a mini-batch of experiences uniformly from the memory. Minibatch size: $\\text{batch_size}$\n",
    "> - for each experience compute the new Q-learning estimate: $\\hat{Q} = r + \\gamma max_{a'} Q(s',a',\\textbf{w})$ (you will need the *Predict* method of the keras NN to get all the $Q$s)   \n",
    "> - SGD step to adjust the $\\textbf{w}$ with  $L(\\textbf{w}) = \\frac{1}{2}(\\hat{Q} - Q)^2$ (using the *Fit* method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "class DQN_Brain:\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, learning_rate=.005, mem_size=5000, batch_size=64, gamma=1.):\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.memory = deque(maxlen=mem_size) # Define our experience replay bucket as a deque with size mem_size.\n",
    "        self.model = build_NN(input_dim, output_dim, learning_rate)\n",
    "        \n",
    "        \n",
    "    def act(self, state, explore_p):\n",
    "        # With probability explore_p, randomly pick an action\n",
    "        if explore_p > np.random.rand():\n",
    "            return np.random.randint(self.output_dim)\n",
    "        # Otherwise, find the action that should maximize future rewards according to our current Q-function policy.\n",
    "        else:\n",
    "            return np.argmax(self.model.predict(np.array([state])))\n",
    "            \n",
    "        \n",
    "    def remember(self, state, action, next_state, reward):\n",
    "        # Create a blank state. Serves as next_state if this was the last experience tuple before the epoch ended.\n",
    "        terminal_state = np.array([None]*self.input_dim) \n",
    "        # Add experience tuple to bucket. Bucket is a deque, so older tuple falls out on overflow.\n",
    "        self.memory.append((state, action, terminal_state if next_state is None else next_state, reward))\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "\n",
    "        # Only conduct a replay if we have enough experience to sample from.\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        # Pick random indices from the bucket without replacement. batch_size determines number of samples.\n",
    "        idx = np.random.choice(len(self.memory), size=self.batch_size, replace=False)\n",
    "        minibatch = np.array(self.memory)[idx]\n",
    "\n",
    "        # Extract the experience from our sample\n",
    "        states = np.array(list(minibatch[:,0]))\n",
    "        actions = minibatch[:,1]\n",
    "        rewards = np.array(minibatch[:,3])\n",
    "        next_states = np.array(list(minibatch[:,2]))\n",
    "        \n",
    "        # Compute a new estimate for each Q-value\n",
    "        estimate = rewards + self.gamma * np.amax(self.model.predict(next_states), axis=1)\n",
    "\n",
    "        # Get the network's current Q-value predictions for the states in this sample.\n",
    "        predictions = self.model.predict(states)\n",
    "        # Update the network's predictions with the new predictions we have.\n",
    "        for i in range(len(predictions)):\n",
    "            # Flag states as terminal (the last state before a epoch ended).\n",
    "            terminal_state = (next_states[i] == np.array([None]*self.input_dim)).all()\n",
    "            # Update each state's Q-value prediction with our new estimate.\n",
    "            # Terminal states have no future, so set their Q-value to their immediate reward.\n",
    "            predictions[i][actions[i]] = rewards[i] if terminal_state else estimate[i]\n",
    "\n",
    "        # Propagate the new predictions through our network.\n",
    "        self.model.fit(states, predictions, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Learning\n",
    "    \n",
    "With the right recipe of hyperparameters, the cartPole should converge to a good strategy for balancing the pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_ep_step = 300\n",
    "batch_size = 64\n",
    "gamma = 0.98\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Epsilon greedy rule\n",
    "\n",
    "# The expolration probability decays as the power -2 of the number of training steps.\n",
    "# After a chosen number of steps the exploration probability fixes on a small value\n",
    "def eps_rule_sq_decay(training_step):\n",
    "    exp = 1.6\n",
    "    #if training_step > 100000:\n",
    "    #    return (100 / 520)**(exp)\n",
    "    return (100 / (100 + training_step*0.01))**(exp)\n",
    "\n",
    "\n",
    "# Stop rules\n",
    "\n",
    "# The learning stops if the number of training steps is larger than a chosen threshold\n",
    "def stop_after_steps(training_step, reward_trajectory):\n",
    "    if training_step > 30000:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# The learning stops if the average reward is close to the maximum after 10 consecutive episodes.\n",
    "# Use this rule only if you know that the algorithm will learn at some point!\n",
    "def stop_if_success(training_step, reward_trajectory):\n",
    "    if training_step > 10000:\n",
    "        if (np.mean(reward_trajectory[-50:]) > max_ep_step-20).all() and reward_trajectory[-1] == max_ep_step :\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 20, Steps: 410, Last reward: 27.0, Explore P: 0.9377322078700748\n",
      "Episode: 40, Steps: 869, Last reward: 25.0, Explore P: 0.8751785361365467\n",
      "Episode: 60, Steps: 1391, Last reward: 78.0, Explore P: 0.8118971876123123\n",
      "Episode: 80, Steps: 2353, Last reward: 46.0, Explore P: 0.7131224252445771\n",
      "Episode: 100, Steps: 3221, Last reward: 65.0, Explore P: 0.6397011208013013\n",
      "Episode: 120, Steps: 4231, Last reward: 44.0, Explore P: 0.5686215700416029\n",
      "Episode: 140, Steps: 6151, Last reward: 32.0, Explore P: 0.46438793984587906\n",
      "Episode: 160, Steps: 7925, Last reward: 25.0, Explore P: 0.39306587134760124\n",
      "Episode: 180, Steps: 9795, Last reward: 41.0, Explore P: 0.33535994539904923\n",
      "Episode: 200, Steps: 11573, Last reward: 174.0, Explore P: 0.2922423358322313\n",
      "Episode: 220, Steps: 14252, Last reward: 121.0, Explore P: 0.24232817114840408\n",
      "Episode: 240, Steps: 16609, Last reward: 133.0, Explore P: 0.20890763587910735\n",
      "Episode: 260, Steps: 19483, Last reward: 136.0, Explore P: 0.17729044254835438\n",
      "Episode: 280, Steps: 23665, Last reward: 300.0, Explore P: 0.14338846313271794\n",
      "Episode: 300, Steps: 28196, Last reward: 82.0, Explore P: 0.11715784765845476\n",
      "Episode: 320, Steps: 32654, Last reward: 19.0, Explore P: 0.09818934809035455\n",
      "Episode: 340, Steps: 37231, Last reward: 300.0, Explore P: 0.08341354423723377\n",
      "Episode: 360, Steps: 42246, Last reward: 300.0, Explore P: 0.07097658934597688\n",
      "Episode: 380, Steps: 47165, Last reward: 300.0, Explore P: 0.06145987427017605\n",
      "Episode: 400, Steps: 52368, Last reward: 300.0, Explore P: 0.05346395617256181\n",
      "Episode: 420, Steps: 57562, Last reward: 300.0, Explore P: 0.04704094139624552\n",
      "Episode: 440, Steps: 63080, Last reward: 268.0, Explore P: 0.04148798458972552\n",
      "Episode: 460, Steps: 68337, Last reward: 300.0, Explore P: 0.0371238409022291\n",
      "Episode: 480, Steps: 72429, Last reward: 103.0, Explore P: 0.03421936531094639\n",
      "Episode: 500, Steps: 77450, Last reward: 217.0, Explore P: 0.031130371102185965\n",
      "Episode: 520, Steps: 81986, Last reward: 300.0, Explore P: 0.02871079548328071\n",
      "Episode: 540, Steps: 87605, Last reward: 125.0, Explore P: 0.026112274031388834\n",
      "Episode: 560, Steps: 92974, Last reward: 300.0, Explore P: 0.02396822467108572\n",
      "Episode: 580, Steps: 98346, Last reward: 265.0, Explore P: 0.022095273832636448\n",
      "Episode: 600, Steps: 103499, Last reward: 300.0, Explore P: 0.020512223683316486\n",
      "Episode: 620, Steps: 108643, Last reward: 166.0, Explore P: 0.01910788454405988\n",
      "Episode: 640, Steps: 113572, Last reward: 300.0, Explore P: 0.017903085214439316\n",
      "Episode: 660, Steps: 118428, Last reward: 300.0, Explore P: 0.016832338218674445\n",
      "Episode: 680, Steps: 123993, Last reward: 145.0, Explore P: 0.01572782335540572\n",
      "Episode: 700, Steps: 128466, Last reward: 300.0, Explore P: 0.01492282223562607\n",
      "Episode: 720, Steps: 134029, Last reward: 300.0, Explore P: 0.014011353407851672\n",
      "Episode: 740, Steps: 137877, Last reward: 300.0, Explore P: 0.013432566205219591\n",
      "Episode: 760, Steps: 143802, Last reward: 300.0, Explore P: 0.012614232378637097\n",
      "Episode: 780, Steps: 149403, Last reward: 300.0, Explore P: 0.011912574095770904\n",
      "Episode: 800, Steps: 154368, Last reward: 300.0, Explore P: 0.011342071135234107\n",
      "Episode: 820, Steps: 160212, Last reward: 300.0, Explore P: 0.010725454885335496\n",
      "Episode: 840, Steps: 165567, Last reward: 300.0, Explore P: 0.010206841691247024\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "env._max_episode_steps = max_ep_step\n",
    "\n",
    "brain = DQN_Brain(input_dim=4, output_dim=2, batch_size=batch_size, gamma=gamma, learning_rate=learning_rate)\n",
    "total_R = Learn(env, brain, stop_if_success, eps_rule_sq_decay, print_every_ep=20)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the cumulative-reward-per-episode trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5406caa860>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.xlabel('N episodes')\n",
    "plt.ylim(0, 310)\n",
    "plt.ylabel('Total reward per episode')\n",
    "plt.plot(total_R, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying the strategy for a longer period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 10000.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "env.reset()\n",
    "# The test function will also render the cartPole\n",
    "Test(env, brain.model, 10000, render=True)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_NN(model, directory, name):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(directory + name+ '.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(directory + name + '.h5')\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "#save_NN(brain.model, '', 'keras_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "def load_NN(directory, name):\n",
    "    # load json and create model\n",
    "    json_file = open(directory + name+ '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(directory + name + '.h5')\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "trained_model = load_NN('', 'trained_keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 10000.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "env.reset()\n",
    "\n",
    "Test(env, trained_model, 10000, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
